{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ceeb4e6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import datasets\n",
    "from tempfile import gettempdir\n",
    "from uuid import uuid1\n",
    "import os\n",
    "import json\n",
    "import random\n",
    "from tqdm.auto import trange\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "97353422",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "ds_train = datasets.CIFAR10(gettempdir(), download = True, train = True)\n",
    "ds_test = datasets.CIFAR10(gettempdir(), download = True, train = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "876de445",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading pre-prepared dataset\n"
     ]
    }
   ],
   "source": [
    "# create labels\n",
    "labels = [\n",
    "    \"airplane\",\n",
    "    \"automobile\",\n",
    "    \"bird\",\n",
    "    \"cat\",\n",
    "    \"deer\",\n",
    "    \"dog\",\n",
    "    \"frog\",\n",
    "    \"horse\",\n",
    "    \"ship\",\n",
    "    \"truck\"\n",
    "]\n",
    "class_to_id = {x:i for i,x in enumerate(labels)}\n",
    "\n",
    "# create a target dir\n",
    "target_dir = os.path.join(gettempdir(), \"cifar10-ByTe-train\")\n",
    "if not os.path.exists(target_dir):\n",
    "    print(\"Creating dataset\")\n",
    "    os.makedirs(target_dir, exist_ok=True)\n",
    "\n",
    "    truth = {}\n",
    "    for _, (x, l) in zip(trange(len(ds_train)), ds_train):\n",
    "        fp = os.path.join(target_dir, str(uuid1()) + random.choice([\".png\", \".jpg\", \".tif\"]))\n",
    "        truth[fp] = labels[l]\n",
    "        x.save(fp)\n",
    "        \n",
    "    with open(os.path.join(target_dir, \"truth.json\"), \"w\") as f:\n",
    "        f.write(json.dumps(truth))\n",
    "else:\n",
    "    print(\"Loading pre-prepared dataset\")\n",
    "    with open(os.path.join(target_dir, \"truth.json\"), \"r\") as f:\n",
    "        truth = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cc09eae8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gperc import Consumer, BinaryConfig, Perceiver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6c4e693c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2021-11-17 19:23:08] Creating metadata\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dd928a81f22a429c8ddf3e758d8f50e4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6614d9883f234b80a5bb85a4e886d30c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "caa125e730b14ba6866ca4da294b05d2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "606e6e23a23040999635f08079974ac0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0e02620662794ff7bf6d4b89bad56ed7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "83185422d3f645a1b1ece3fe52ee1080",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "65241c05cfd14351a1a3036873008a2a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "daebd1e5dc564d80b46dde58bf696692",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "af79092175fe4e57923b98efa7b227ac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e437cf0387cf4f60beabb3236ec5a574",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data = Consumer(truth, n_bytes=1, class_to_id=class_to_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "653dabae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<gperc Consumer {\n",
       "  \"total_samples\": 50000,\n",
       "  \"mode\": null,\n",
       "  \"n_classes\": 10,\n",
       "  \"n_bytes\": 1,\n",
       "  \"seqlen\": 3447,\n",
       "  \"vocab_size\": 257,\n",
       "  \"style\": \"diff\"\n",
       "}>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "83bfd8ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 3447])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[0][\"input_array\"].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "12f8fc98",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "bytearray(b'/var/folders/dg/b9jch2h97kj2qbcsxj7kb6rc0000gn/T/cifar10-ByTe-train/0f31ac58-47ad-11ec-b801-1e00ea1e7259.tif: TIFF image data, little-endian, direntries=10, height=32, bps=134, compression=none, PhotometricIntepretation=RGB, width=32\\nII*\\x00\\x08\\x00\\x00\\x00\\n\\x00\\x00\\x01\\x04\\x00\\x01\\x00')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# let's just check the header always to [:-1] to ignore the <EOF> otherwise it wont be able to convert\n",
    "# to bytes\n",
    "bytearray(data[0][\"input_array\"][0].tolist()[:-1])[:250]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7c8df460",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<gperc Consumer {\n",
       "  \"total_samples\": 50000,\n",
       "  \"mode\": \"supervised\",\n",
       "  \"n_classes\": 10,\n",
       "  \"n_bytes\": 1,\n",
       "  \"seqlen\": 3447,\n",
       "  \"vocab_size\": 257,\n",
       "  \"style\": \"diff\"\n",
       "}>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.set_supervised_mode()\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1216baf4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_array': tensor([[ 47, 118,  97,  ...,  92,  72, 256]]),\n",
       " 'attention_mask': tensor([[1, 1, 1,  ..., 1, 1, 1]]),\n",
       " 'class': tensor([6])}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[0, \"supervised\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "76ed6fe7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_array': tensor([[ 47, 118,  97,  ...,  92,  72, 256]]),\n",
       " 'attention_mask': tensor([[1, 1, 1,  ..., 1, 1, 1]])}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[None]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1c13ddac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "365578"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create the model\n",
    "config = BinaryConfig(\n",
    "    seqlen = data.seqlen,\n",
    "    vocab_size = data.vocab_size,\n",
    "    latent_dim = 32,\n",
    "    eot_token = data.EOF_ID,\n",
    "    n_classes = len(class_to_id),\n",
    "    ffw_ratio=1.0\n",
    ")\n",
    "model = Perceiver(config)\n",
    "model.num_parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "aa6cc0cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ship', 'ship', 'ship']\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    out = model(**data[[0, 1, 2]])\n",
    "    print([labels[i] for i in out.argmax(-1).tolist()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fcd81b37",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.create_batches(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "600a624b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2e46665d97564abcb079d8e2344f0def",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/dg/b9jch2h97kj2qbcsxj7kb6rc0000gn/T/ipykernel_20392/3977354610.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m     \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m     \u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniforge3/envs/nbx/lib/python3.9/site-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    305\u001b[0m                 \u001b[0mcreate_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    306\u001b[0m                 inputs=inputs)\n\u001b[0;32m--> 307\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    308\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    309\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniforge3/envs/nbx/lib/python3.9/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    152\u001b[0m         \u001b[0mretain_graph\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    153\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 154\u001b[0;31m     Variable._execution_engine.run_backward(\n\u001b[0m\u001b[1;32m    155\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    156\u001b[0m         allow_unreachable=True, accumulate_grad=True)  # allow_unreachable flag\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# training the model\n",
    "optim = torch.optim.Adam(model.parameters(), 0.001)\n",
    "n_epochs = 1000\n",
    "pbar = trange(n_epochs)\n",
    "device = \"cpu\" if not torch.cuda.is_available() else \"cuda:0\"\n",
    "model = model.to(device)\n",
    "\n",
    "all_losses = []; all_acc = []\n",
    "\n",
    "for epoch in pbar:\n",
    "    batch = data.get_next_batch(\"supervised\")\n",
    "    batch = {k:v.to(device) for k,v in batch.items()}\n",
    "    out = model(batch[\"input_array\"])\n",
    "    target = batch[\"class\"].to(device)\n",
    "    loss = torch.nn.functional.cross_entropy(out, target)\n",
    "    \n",
    "    optim.zero_grad()\n",
    "    loss.backward()\n",
    "    optim.step()\n",
    "    \n",
    "    all_losses.append(loss.item())\n",
    "    acc = out.argmax(-1).eq(target).float().mean()\n",
    "    all_acc.append(acc.item())\n",
    "    pbar.set_description(f\"loss: {all_losses[-1]:.5f} | acc: {all_acc[-1]:.2f}\")\n",
    "\n",
    "    if all_acc[-1] == 1.0:\n",
    "      # memorisation complete\n",
    "      break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e72e3b8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
