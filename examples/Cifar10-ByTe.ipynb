{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "64bb65d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import datasets\n",
    "from tempfile import gettempdir\n",
    "from uuid import uuid1\n",
    "import os\n",
    "import json\n",
    "import random\n",
    "from tqdm.auto import trange\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f1a801e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "ds_train = datasets.CIFAR10(gettempdir(), download = True, train = True)\n",
    "ds_test = datasets.CIFAR10(gettempdir(), download = True, train = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "79d1a8c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading pre-prepared dataset\n"
     ]
    }
   ],
   "source": [
    "# create labels\n",
    "labels = [\n",
    "    \"airplane\",\n",
    "    \"automobile\",\n",
    "    \"bird\",\n",
    "    \"cat\",\n",
    "    \"deer\",\n",
    "    \"dog\",\n",
    "    \"frog\",\n",
    "    \"horse\",\n",
    "    \"ship\",\n",
    "    \"truck\"\n",
    "]\n",
    "class_to_id = {x:i for i,x in enumerate(labels)}\n",
    "\n",
    "# create a target dir\n",
    "target_dir = os.path.join(gettempdir(), \"cifar10-ByTe-train\")\n",
    "if not os.path.exists(target_dir):\n",
    "    print(\"Creating dataset\")\n",
    "    os.makedirs(target_dir, exist_ok=True)\n",
    "\n",
    "    truth = {}\n",
    "    for _, (x, l) in zip(trange(len(ds_train)), ds_train):\n",
    "        fp = os.path.join(target_dir, str(uuid1()) + random.choice([\".png\", \".jpg\", \".tif\"]))\n",
    "        truth[fp] = labels[l]\n",
    "        x.save(fp)\n",
    "        \n",
    "    with open(os.path.join(target_dir, \"truth.json\"), \"w\") as f:\n",
    "        f.write(json.dumps(truth))\n",
    "else:\n",
    "    print(\"Loading pre-prepared dataset\")\n",
    "    with open(os.path.join(target_dir, \"truth.json\"), \"r\") as f:\n",
    "        truth = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1c98ba08",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gperc import Consumer, BinaryConfig, Perceiver, ArrowConsumer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c9e93607",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration 804009c286e1c7b157519e9cf95893bc5b2b5c6c132b210f8a0935fab09e4417\n",
      "Reusing dataset binary_arrow_builder (/Users/yashbonde/.cache/huggingface/datasets/binary_arrow_builder/804009c286e1c7b157519e9cf95893bc5b2b5c6c132b210f8a0935fab09e4417/0.0.0)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b21cc50139904318b013a3e92341ff5e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenising the entire datset, this can takes some time (will use all cores) ...\n"
     ]
    }
   ],
   "source": [
    "data = ArrowConsumer(truth, n_bytes=1, class_to_id=class_to_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fc25454c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<gperc ArrowConsumer {\n",
       "  \"total_samples\": 50000,\n",
       "  \"mode\": \"F2\",\n",
       "  \"n_classes\": 10,\n",
       "  \"n_bytes\": 1,\n",
       "  \"seqlen\": 3323,\n",
       "  \"vocab_size\": 257,\n",
       "  \"style\": \"diff\"\n",
       "}>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b62a28f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 3323])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[0][\"input_array\"].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a28006e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "bytearray(b'/var/folders/dg/b9jch2h97kj2qbcsxj7kb6rc0000gn/T/cifar10-ByTe-train/0f344d5a-47ad-11ec-b801-1e00ea1e7259.tif|II*\\x00\\x08\\x00\\x00\\x00\\n\\x00\\x00\\x01\\x04\\x00\\x01\\x00\\x00\\x00 \\x00\\x00\\x00\\x01\\x01\\x04\\x00\\x01\\x00\\x00\\x00 \\x00\\x00\\x00\\x02\\x01\\x03\\x00\\x03\\x00\\x00\\x00\\x86\\x00\\x00\\x00\\x03\\x01\\x03\\x00\\x01\\x00\\x00\\x00\\x01\\x00\\x00\\x00\\x06\\x01\\x03\\x00\\x01\\x00\\x00\\x00\\x02\\x00\\x00\\x00\\x11\\x01\\x04\\x00\\x01\\x00\\x00\\x00\\x8c\\x00\\x00\\x00\\x15\\x01\\x03\\x00\\x01\\x00\\x00\\x00\\x03\\x00\\x00\\x00\\x16\\x01\\x04\\x00\\x01\\x00\\x00\\x00 \\x00\\x00\\x00\\x17\\x01\\x04\\x00\\x01\\x00\\x00\\x00\\x00\\x0c\\x00\\x00\\x1c\\x01\\x03\\x00\\x01\\x00\\x00\\x00\\x01\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x08\\x00\\x08\\x00\\x08\\x00\\xca')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# let's just check the header always to [:-1] to ignore the <EOF> otherwise it wont be able to convert\n",
    "# to bytes\n",
    "bytearray(data[0][\"input_array\"][0].tolist()[:-1])[:250]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cb7111ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_array': tensor([[ 47, 118,  97,  ..., 243,   0, 256]]),\n",
       " 'attention_mask': tensor([[1, 1, 1,  ..., 1, 1, 1]]),\n",
       " 'class': tensor([0])}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[None]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "770f7043",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "257962"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create the model\n",
    "config = BinaryConfig(\n",
    "    seqlen = data.seqlen,\n",
    "    vocab_size = data.vocab_size,\n",
    "    latent_dim = 32,\n",
    "    eot_token = data.EOF_ID,\n",
    "    n_classes = len(class_to_id),\n",
    "    ffw_ratio=1.0\n",
    ")\n",
    "model = Perceiver(config)\n",
    "model.num_parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5596925f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['automobile', 'bird', 'bird']\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    out = model(data[[0, 1, 2]][\"input_array\"])\n",
    "    print([labels[i] for i in out.argmax(-1).tolist()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "97425aaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.create_batches(32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "bf80769d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f17f03f21b8e4f1db4aa6701bc88a810",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.03s]\tGetting data\n",
      "[1.30s]\tForward pass\n",
      "[0.67s]\tOptim Step\n",
      "[0.02s]\tGetting data\n",
      "[1.17s]\tForward pass\n",
      "[0.59s]\tOptim Step\n",
      "[0.02s]\tGetting data\n",
      "[1.17s]\tForward pass\n",
      "[0.59s]\tOptim Step\n",
      "[0.02s]\tGetting data\n",
      "[1.18s]\tForward pass\n",
      "[0.58s]\tOptim Step\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/dg/b9jch2h97kj2qbcsxj7kb6rc0000gn/T/ipykernel_62427/2605353036.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m         \u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m         \u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniforge3/envs/nbx/lib/python3.9/site-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    305\u001b[0m                 \u001b[0mcreate_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    306\u001b[0m                 inputs=inputs)\n\u001b[0;32m--> 307\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    308\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    309\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniforge3/envs/nbx/lib/python3.9/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    152\u001b[0m         \u001b[0mretain_graph\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    153\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 154\u001b[0;31m     Variable._execution_engine.run_backward(\n\u001b[0m\u001b[1;32m    155\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    156\u001b[0m         allow_unreachable=True, accumulate_grad=True)  # allow_unreachable flag\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from time import time\n",
    "\n",
    "class Timer:\n",
    "    def __init__(self, msg = \"\"):\n",
    "        self.msg = msg\n",
    "    \n",
    "    def __enter__(self, *a):\n",
    "        self.st = time()\n",
    "        \n",
    "    def __exit__(self, *a):\n",
    "        print(f\"[{time()-self.st:.2f}s]\\t{self.msg}\")\n",
    "        \n",
    "    \n",
    "\n",
    "# training the model\n",
    "optim = torch.optim.Adam(model.parameters(), 0.001)\n",
    "n_epochs = 1000\n",
    "pbar = trange(n_epochs)\n",
    "device = \"cpu\" if not torch.cuda.is_available() else \"cuda:0\"\n",
    "model = model.to(device)\n",
    "\n",
    "all_losses = []; all_acc = []\n",
    "\n",
    "for epoch in pbar:\n",
    "    st = time()\n",
    "    with Timer(\"Getting data\"):\n",
    "        batch = data.get_next_batch()\n",
    "        \n",
    "    batch = {k:v.to(device) for k,v in batch.items()}\n",
    "    \n",
    "    with Timer(\"Forward pass\"):\n",
    "        out = model(batch[\"input_array\"])\n",
    "\n",
    "    target = batch[\"class\"].to(device)\n",
    "    \n",
    "    with Timer(\"Optim Step\"):\n",
    "        loss = torch.nn.functional.cross_entropy(out, target)\n",
    "\n",
    "        optim.zero_grad()\n",
    "        loss.backward()\n",
    "        optim.step()\n",
    "    \n",
    "    all_losses.append(loss.item())\n",
    "    acc = out.argmax(-1).eq(target).float().mean()\n",
    "    all_acc.append(acc.item())\n",
    "    pbar.set_description(f\"loss: {all_losses[-1]:.5f} | acc: {all_acc[-1]:.2f}\")\n",
    "\n",
    "    if all_acc[-1] == 1.0:\n",
    "      # memorisation complete\n",
    "      break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c36d516f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
