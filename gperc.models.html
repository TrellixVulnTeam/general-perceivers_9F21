<!doctype html>
<html class="no-js">
  <head><meta charset="utf-8"/>
    <meta name="viewport" content="width=device-width,initial-scale=1"/>
    <meta name="color-scheme" content="light dark"><meta name="generator" content="Docutils 0.17.1: http://docutils.sourceforge.net/" />
<link rel="index" title="Index" href="genindex.html" /><link rel="search" title="Search" href="search.html" /><link rel="next" title="Utils" href="gperc.utils.html" /><link rel="prev" title="gperc Data" href="gperc.data.html" />

    <meta name="generator" content="sphinx-4.2.0, furo 2021.10.09"/>
        <title>gperc Architecture - gperc 0.4 documentation</title>
      <link rel="stylesheet" type="text/css" href="_static/pygments.css" />
    <link rel="stylesheet" type="text/css" href="_static/styles/furo.css?digest=0254c309f5cadf746f1a613e7677379ac9c8cdcd" />
    <link rel="stylesheet" type="text/css" href="_static/styles/furo-extensions.css?digest=16fb25fabf47304eee183a5e9af80b1ba98259b1" />
    
    


<style>
  body {
    --color-code-background: #f8f8f8;
  --color-code-foreground: black;
  
  }
  body[data-theme="dark"] {
    --color-code-background: #202020;
  --color-code-foreground: #d0d0d0;
  
  }
  @media (prefers-color-scheme: dark) {
    body:not([data-theme="light"]) {
      --color-code-background: #202020;
  --color-code-foreground: #d0d0d0;
  
    }
  }
</style></head>
  <body>
    <script>
      document.body.dataset.theme = localStorage.getItem("theme") || "auto";
    </script>
    
<svg xmlns="http://www.w3.org/2000/svg" style="display: none;">
  <symbol id="svg-toc" viewBox="0 0 24 24">
    <title>Contents</title>
    <svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="1.5" stroke-linecap="round" stroke-linejoin="round">
      <path stroke="none" d="M0 0h24v24H0z" />
      <line x1="4" y1="6" x2="20" y2="6" />
      <line x1="10" y1="12" x2="20" y2="12" />
      <line x1="6" y1="18" x2="20" y2="18" />
    </svg>
  </symbol>
  <symbol id="svg-menu" viewBox="0 0 24 24">
    <title>Menu</title>
    <svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather-menu">
      <line x1="3" y1="12" x2="21" y2="12"></line>
      <line x1="3" y1="6" x2="21" y2="6"></line>
      <line x1="3" y1="18" x2="21" y2="18"></line>
    </svg>
  </symbol>
  <symbol id="svg-arrow-right" viewBox="0 0 24 24">
    <title>Expand</title>
    <svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather-chevron-right">
      <polyline points="9 18 15 12 9 6"></polyline>
    </svg>
  </symbol>
  <symbol id="svg-sun" viewBox="0 0 24 24">
    <title>Light mode</title>
    <svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="1.5" stroke-linecap="round" stroke-linejoin="round" class="feather-sun">
      <circle cx="12" cy="12" r="5"></circle>
      <line x1="12" y1="1" x2="12" y2="3"></line>
      <line x1="12" y1="21" x2="12" y2="23"></line>
      <line x1="4.22" y1="4.22" x2="5.64" y2="5.64"></line>
      <line x1="18.36" y1="18.36" x2="19.78" y2="19.78"></line>
      <line x1="1" y1="12" x2="3" y2="12"></line>
      <line x1="21" y1="12" x2="23" y2="12"></line>
      <line x1="4.22" y1="19.78" x2="5.64" y2="18.36"></line>
      <line x1="18.36" y1="5.64" x2="19.78" y2="4.22"></line>
    </svg>
  </symbol>
  <symbol id="svg-moon" viewBox="0 0 24 24">
    <title>Dark mode</title>
    <svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="1.5" stroke-linecap="round" stroke-linejoin="round" class="icon-tabler-moon">
      <path stroke="none" d="M0 0h24v24H0z" fill="none" />
      <path d="M12 3c.132 0 .263 0 .393 0a7.5 7.5 0 0 0 7.92 12.446a9 9 0 1 1 -8.313 -12.454z" />
    </svg>
  </symbol>
  <symbol id="svg-sun-half" viewBox="0 0 24 24">
    <title>Auto light/dark mode</title>
    <svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="1.5" stroke-linecap="round" stroke-linejoin="round" class="icon-tabler-shadow">
      <path stroke="none" d="M0 0h24v24H0z" fill="none"/>
      <circle cx="12" cy="12" r="9" />
      <path d="M13 12h5" />
      <path d="M13 15h4" />
      <path d="M13 18h1" />
      <path d="M13 9h4" />
      <path d="M13 6h1" />
    </svg>
  </symbol>
</svg>

<input type="checkbox" class="sidebar-toggle" name="__navigation" id="__navigation">
<input type="checkbox" class="sidebar-toggle" name="__toc" id="__toc">
<label class="overlay sidebar-overlay" for="__navigation">
  <div class="visually-hidden">Hide navigation sidebar</div>
</label>
<label class="overlay toc-overlay" for="__toc">
  <div class="visually-hidden">Hide table of contents sidebar</div>
</label>



<div class="page">
  <header class="mobile-header">
    <div class="header-left">
      <label class="nav-overlay-icon" for="__navigation">
        <div class="visually-hidden">Toggle site navigation sidebar</div>
        <i class="icon"><svg><use href="#svg-menu"></use></svg></i>
      </label>
    </div>
    <div class="header-center">
      <a href="index.html"><div class="brand">gperc 0.4 documentation</div></a>
    </div>
    <div class="header-right">
      <div class="theme-toggle-container theme-toggle-header">
        <button class="theme-toggle">
          <div class="visually-hidden">Toggle Light / Dark / Auto color theme</div>
          <svg class="theme-icon-when-auto"><use href="#svg-sun-half"></use></svg>
          <svg class="theme-icon-when-dark"><use href="#svg-moon"></use></svg>
          <svg class="theme-icon-when-light"><use href="#svg-sun"></use></svg>
        </button>
      </div>
      <label class="toc-overlay-icon toc-header-icon" for="__toc">
        <div class="visually-hidden">Toggle table of contents sidebar</div>
        <i class="icon"><svg><use href="#svg-toc"></use></svg></i>
      </label>
    </div>
  </header>
  <aside class="sidebar-drawer">
    <div class="sidebar-container">
      
      <div class="sidebar-sticky"><a class="sidebar-brand" href="index.html">
  
  
  <span class="sidebar-brand-text">gperc 0.4 documentation</span>
  
</a><form class="sidebar-search-container" method="get" action="search.html" role="search">
  <input class="sidebar-search" placeholder=Search name="q" aria-label="Search">
  <input type="hidden" name="check_keywords" value="yes">
  <input type="hidden" name="area" value="default">
</form>
<div id="searchbox"></div><div class="sidebar-scroll"><div class="sidebar-tree">
  <p class="caption" role="heading"><span class="caption-text">Stories</span></p>
<ul>
<li class="toctree-l1 has-children"><a class="reference internal" href="stories.html">Stories</a><input class="toctree-checkbox" id="toctree-checkbox-1" name="toctree-checkbox-1" role="switch" type="checkbox"/><label for="toctree-checkbox-1"><div class="visually-hidden">Toggle child pages in navigation</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="stories.1.html">1. Quick Dopamine</a></li>
<li class="toctree-l2"><a class="reference internal" href="stories.2.html">2. Distributed Computing</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="remote.html">YoCo (Remote Execution)</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Documentation</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="gperc.cli.html">gperc CLI</a></li>
<li class="toctree-l1"><a class="reference internal" href="gperc.configs.html">gperc Configurations</a></li>
<li class="toctree-l1"><a class="reference internal" href="gperc.data.html">gperc Data</a></li>
<li class="toctree-l1 current current-page"><a class="current reference internal" href="#">gperc Architecture</a></li>
<li class="toctree-l1"><a class="reference internal" href="gperc.utils.html">Utils</a></li>
<li class="toctree-l1"><a class="reference internal" href="testing.html">Tests</a></li>
</ul>

</div>
</div>
      </div>
      
    </div>
  </aside>
  <div class="main">
    <div class="content">
      <div class="article-container">
        <div class="content-icon-container">
          <div class="theme-toggle-container theme-toggle-content">
            <button class="theme-toggle">
              <div class="visually-hidden">Toggle Light / Dark / Auto color theme</div>
              <svg class="theme-icon-when-auto"><use href="#svg-sun-half"></use></svg>
              <svg class="theme-icon-when-dark"><use href="#svg-moon"></use></svg>
              <svg class="theme-icon-when-light"><use href="#svg-sun"></use></svg>
            </button>
          </div>
          <label class="toc-overlay-icon toc-content-icon" for="__toc">
            <div class="visually-hidden">Toggle table of contents sidebar</div>
            <i class="icon"><svg><use href="#svg-toc"></use></svg></i>
          </label>
        </div>
        <article role="main">
          <section id="module-gperc.models">
<span id="gperc-architecture"></span><h1>gperc Architecture<a class="headerlink" href="#module-gperc.models" title="Permalink to this headline">¶</a></h1>
<section id="perceiver-model">
<h2>Perceiver Model<a class="headerlink" href="#perceiver-model" title="Permalink to this headline">¶</a></h2>
<p>This file has code on the neural network of the pervceiver architecture. <code class="docutils literal notranslate"><span class="pre">gperc.models.Perceiver</span></code> sits at
the heart of this project. Use <code class="docutils literal notranslate"><span class="pre">Perceiver</span></code> for <a class="reference external" href="stories.1.html">everyday</a> use of the model, when you want
to train really large models with model parallellism read <a class="reference external" href="stories.2.html">here</a>.</p>
<section id="distributed">
<h3>Distributed<a class="headerlink" href="#distributed" title="Permalink to this headline">¶</a></h3>
<p><code class="docutils literal notranslate"><span class="pre">gperc</span></code> out-of-box can handle distributed model parallel training with
<a class="reference external" href="gperc.models.html#gperc.models.get_distributed_model">get_distributed_model()</a> During distributed training
and inference with <code class="docutils literal notranslate"><span class="pre">torch.distributed.pipeline.sync.Pipe</span></code>
(<a class="reference external" href="https://pytorch.org/tutorials/intermediate/pipeline_tutorial.html">read tutorial</a>) the input has to be a
<code class="docutils literal notranslate"><span class="pre">nn.Sequential</span></code> object.</p>
</section>
<section id="documentation">
<h3>Documentation<a class="headerlink" href="#documentation" title="Permalink to this headline">¶</a></h3>
<dl class="py function">
<dt class="sig sig-object py" id="gperc.models.build_position_encoding">
<span class="sig-prename descclassname"><span class="pre">gperc.models.</span></span><span class="sig-name descname"><span class="pre">build_position_encoding</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">position_encoding_type</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">config</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">num_index_items</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">emb_dim</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/gperc/models.html#build_position_encoding"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#gperc.models.build_position_encoding" title="Permalink to this definition">¶</a></dt>
<dd><p>Get the positional encoding matrix. If <code class="docutils literal notranslate"><span class="pre">position_encoding_type</span> <span class="pre">==</span> <span class="pre">"trainable"</span></code> then a random normal
matrix is returned, if it is “sinusoid” then</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>position_encoding_type</strong> (<em>str</em>) – type of embedding, should be one of “trainable”, “sinusoid”</p></li>
<li><p><strong>config</strong> – <code class="docutils literal notranslate"><span class="pre">gperc.PerceiverConfig</span></code></p></li>
<li><p><strong>num_index_items</strong> (<em>int</em>) – number of items in the embedding, eg. <code class="docutils literal notranslate"><span class="pre">vocab_size</span></code></p></li>
<li><p><strong>emb_dim</strong> (<em>int</em>) – embedding dimension</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>Item that can be used as a parameter in a <code class="docutils literal notranslate"><span class="pre">torch.nn.Embedding</span></code></p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><code class="docutils literal notranslate"><span class="pre">torch.nn.Parameter</span></code></p>
</dd>
</dl>
</dd></dl>
<dl class="py class">
<dt class="sig sig-object py" id="gperc.models.Block">
<em class="property"><span class="pre">class</span> </em><span class="sig-prename descclassname"><span class="pre">gperc.models.</span></span><span class="sig-name descname"><span class="pre">Block</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">Any</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">Any</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/gperc/models.html#Block"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#gperc.models.Block" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">torch.nn.</span></code></p>
<p>Generic block with Attention and MLP layers</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>kv_dim</strong> (<em>int</em>) – dimension of the key-value embeddings</p></li>
<li><p><strong>q_dim</strong> (<em>int</em>) – dimension of the query embeddings</p></li>
<li><p><strong>num_heads</strong> (<em>int</em>) – number of heads in the multihead attention</p></li>
<li><p><strong>ffw_dim</strong> (<em>int</em>) – dimension of the feed-forward layer</p></li>
<li><p><strong>dropout</strong> (<em>float</em><em>, </em><em>optional</em>) – dropout rate</p></li>
<li><p><strong>add_residual</strong> (<em>bool</em><em>, </em><em>optional</em>) – whether to add residual to the query</p></li>
</ul>
</dd>
</dl>
<dl class="py method">
<dt class="sig sig-object py" id="gperc.models.Block.forward">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">kv</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">q</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">attn_mask</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/gperc/models.html#Block.forward"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#gperc.models.Block.forward" title="Permalink to this definition">¶</a></dt>
<dd><p>Forward pass of the block that taken in a a key-value tensor and a query tensor and performs
the attention and mlp layers. Since it consumes <code class="docutils literal notranslate"><span class="pre">kv</span></code> and <code class="docutils literal notranslate"><span class="pre">q</span></code> seperately, the blocks are responisble
for cross attention like features. Returns a</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>kv</strong> (<em>torch.Tensor</em>) – tensor to extract information from</p></li>
<li><p><strong>q</strong> (<em>torch.Tensor</em>) – tensor for querying the information</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>tuple of output Tensor and Attention matrix</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>Tuple[torch.Tensor, torch.Tensor]</p>
</dd>
</dl>
</dd></dl>
</dd></dl>
<dl class="py class">
<dt class="sig sig-object py" id="gperc.models.Embeddings">
<em class="property"><span class="pre">class</span> </em><span class="sig-prename descclassname"><span class="pre">gperc.models.</span></span><span class="sig-name descname"><span class="pre">Embeddings</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">Any</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">Any</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/gperc/models.html#Embeddings"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#gperc.models.Embeddings" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">torch.nn.</span></code></p>
<dl class="py method">
<dt class="sig sig-object py" id="gperc.models.Embeddings.forward">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input_array</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">attention_mask</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">output_array</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/gperc/models.html#Embeddings.forward"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#gperc.models.Embeddings.forward" title="Permalink to this definition">¶</a></dt>
<dd><p>Takes in either the <code class="docutils literal notranslate"><span class="pre">input_array</span></code> or tuple with 3 items <code class="docutils literal notranslate"><span class="pre">(input_array,</span> <span class="pre">attention_mask,</span> <span class="pre">output)</span></code>
and returns a tuple with 4 values <code class="docutils literal notranslate"><span class="pre">(input_array,</span> <span class="pre">attention_mask,</span> <span class="pre">latent_array,</span> <span class="pre">output_array)</span></code>. If configured
<code class="docutils literal notranslate"><span class="pre">input_array</span></code> can have tokens and will be automatically embedded.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>When using GPipe you need to send in tensors because it will try to send items as microbatches
for each GPU. Now that requires all the inputs to be tensors, so here I have written some
basic dumb heuristic that can set attention_mask and output_array to None if average of the values
in those tensors is -69 and -420 resp.</p>
<p>Image classification task does not require any <code class="docutils literal notranslate"><span class="pre">attention_mask</span></code> you can pass that as a tensor
with values <code class="docutils literal notranslate"><span class="pre">attention_mask</span> <span class="pre">=</span> <span class="pre">torch.tensor([-69.</span> <span class="pre">for</span> <span class="pre">_</span> <span class="pre">in</span> <span class="pre">range(batch_size)])</span></code> and similarly you
can send <code class="docutils literal notranslate"><span class="pre">output_array</span></code> as a tensor with values <code class="docutils literal notranslate"><span class="pre">output_array</span> <span class="pre">=</span> <span class="pre">torch.tensor([-420.</span> <span class="pre">for</span> <span class="pre">_</span> <span class="pre">in</span> <span class="pre">range(batch_size)])</span></code></p>
</div>
</dd></dl>
</dd></dl>
<dl class="py class">
<dt class="sig sig-object py" id="gperc.models.EncoderBlock">
<em class="property"><span class="pre">class</span> </em><span class="sig-prename descclassname"><span class="pre">gperc.models.</span></span><span class="sig-name descname"><span class="pre">EncoderBlock</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">Any</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">Any</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/gperc/models.html#EncoderBlock"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#gperc.models.EncoderBlock" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">torch.nn.</span></code></p>
<p>Encoder Block with postional embeddings</p>
<dl class="py method">
<dt class="sig sig-object py" id="gperc.models.EncoderBlock.forward">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input_array</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">attention_mask</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">latent_array</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">output_array</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/gperc/models.html#EncoderBlock.forward"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#gperc.models.EncoderBlock.forward" title="Permalink to this definition">¶</a></dt>
<dd><p>takes in a tuple with 4 values <code class="docutils literal notranslate"><span class="pre">(input_array,</span> <span class="pre">attention_mask,</span> <span class="pre">latent_array,</span> <span class="pre">output_array)</span></code>
and returns a tuple with 3 items <code class="docutils literal notranslate"><span class="pre">(latent_array,</span> <span class="pre">output_array,</span> <span class="pre">attentions)</span></code></p>
</dd></dl>
</dd></dl>
<dl class="py class">
<dt class="sig sig-object py" id="gperc.models.ProcessorBlock">
<em class="property"><span class="pre">class</span> </em><span class="sig-prename descclassname"><span class="pre">gperc.models.</span></span><span class="sig-name descname"><span class="pre">ProcessorBlock</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">Any</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">Any</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/gperc/models.html#ProcessorBlock"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#gperc.models.ProcessorBlock" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">torch.nn.</span></code></p>
<p>Processor Block without positional embeddings</p>
<dl class="py method">
<dt class="sig sig-object py" id="gperc.models.ProcessorBlock.forward">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">latent_array</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">output_array</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">attentions</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/gperc/models.html#ProcessorBlock.forward"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#gperc.models.ProcessorBlock.forward" title="Permalink to this definition">¶</a></dt>
<dd><p>takes in a tuple with 3 values <code class="docutils literal notranslate"><span class="pre">(latent_array,</span> <span class="pre">output_array,</span> <span class="pre">attentions)</span></code>
and returns a tuple with 3 items <code class="docutils literal notranslate"><span class="pre">(latent_array,</span> <span class="pre">output_array,</span> <span class="pre">attentions)</span></code></p>
</dd></dl>
</dd></dl>
<dl class="py class">
<dt class="sig sig-object py" id="gperc.models.DecoderBlock">
<em class="property"><span class="pre">class</span> </em><span class="sig-prename descclassname"><span class="pre">gperc.models.</span></span><span class="sig-name descname"><span class="pre">DecoderBlock</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">Any</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">Any</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/gperc/models.html#DecoderBlock"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#gperc.models.DecoderBlock" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">torch.nn.</span></code></p>
<dl class="py method">
<dt class="sig sig-object py" id="gperc.models.DecoderBlock.forward">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">latent_array</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">output_array</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">attentions</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/gperc/models.html#DecoderBlock.forward"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#gperc.models.DecoderBlock.forward" title="Permalink to this definition">¶</a></dt>
<dd><p>takes in a tuple with 3 values <code class="docutils literal notranslate"><span class="pre">(latent_array,</span> <span class="pre">output_array,</span> <span class="pre">attentions)</span></code>
and returns a tuple with 2 items <code class="docutils literal notranslate"><span class="pre">(output_logits,</span> <span class="pre">attentions)</span></code></p>
</dd></dl>
</dd></dl>
<dl class="py class">
<dt class="sig sig-object py" id="gperc.models.Perceiver">
<em class="property"><span class="pre">class</span> </em><span class="sig-prename descclassname"><span class="pre">gperc.models.</span></span><span class="sig-name descname"><span class="pre">Perceiver</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">Any</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">Any</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/gperc/models.html#Perceiver"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#gperc.models.Perceiver" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">torch.nn.</span></code></p>
<p>Unassuming Perceiver Architecture that sits at the heart of this project. In practive this is a nice
wrapper around model returned by <code class="docutils literal notranslate"><span class="pre">get_sequential_from_config</span></code> that automatically handles different
types of input in a simple fashion. This is a great approach when using on a single GPU or performing
Data Parallel training on multiple GPUs. When using this for Model Parallel training, you will need to
write your own list etc. read story on <a class="reference external" href="stories.2.html">distributed</a> for more details.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>config</strong> – <code class="docutils literal notranslate"><span class="pre">gperc.PerceiverConfig</span></code> object</p>
</dd>
</dl>
<dl class="py method">
<dt class="sig sig-object py" id="gperc.models.Perceiver.num_parameters">
<span class="sig-name descname"><span class="pre">num_parameters</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">include_non_trainable</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">bool</span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">True</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/gperc/models.html#Perceiver.num_parameters"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#gperc.models.Perceiver.num_parameters" title="Permalink to this definition">¶</a></dt>
<dd><p>function that returns the number of parameters in the modle</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>include_non_trainable</strong> (<em>bool</em><em>, </em><em>optional</em>) – If true includes tensors that have <code class="docutils literal notranslate"><span class="pre">requires_grad=False</span></code> as well</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>number of parameters in the model</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>int</p>
</dd>
</dl>
</dd></dl>
<dl class="py method">
<dt class="sig sig-object py" id="gperc.models.Perceiver.forward">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input_array</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">attention_mask</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">output_array</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">return_attentions</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/gperc/models.html#Perceiver.forward"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#gperc.models.Perceiver.forward" title="Permalink to this definition">¶</a></dt>
<dd><p>Performs the forward pass of the Perceiver.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>input_array</strong> (<em>torch.Tensor</em>) – Input array to the Perceiver, read paper for reference</p></li>
<li><p><strong>attention_mask</strong> (<em>torch.Tensor</em><em>, </em><em>optional</em>) – Mask for the decoder, attends at location with value 1</p></li>
<li><p><strong>output_array</strong> (<em>torch.Tensor</em><em>, </em><em>optional</em>) – Output array to the Perceiver, read paper for reference</p></li>
<li><p><strong>return_attentions</strong> (<em>bool</em><em>, </em><em>optional</em>) – If true returns the attentions as a list</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><dl class="simple">
<dt></dt><dd><p>The output of the Perceiver and the attention matrices</p>
</dd>
</dl>
</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>Tuple[torch.Tensor, List[torch.Tensor]] if <code class="docutils literal notranslate"><span class="pre">return_attentions</span></code> is True else torch.Tensor</p>
</dd>
</dl>
</dd></dl>
</dd></dl>
<dl class="py function">
<dt class="sig sig-object py" id="gperc.models.get_distributed_model">
<span class="sig-prename descclassname"><span class="pre">gperc.models.</span></span><span class="sig-name descname"><span class="pre">get_distributed_model</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">config</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/gperc/models.html#get_distributed_model"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#gperc.models.get_distributed_model" title="Permalink to this definition">¶</a></dt>
<dd><p>This function returns the model that is used for distributed training. This is <strong>not</strong> a wrapper
around <code class="docutils literal notranslate"><span class="pre">Perceiver</span></code> but instead returns a <code class="docutils literal notranslate"><span class="pre">Pipe</span></code> object.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>When using GPipe you need to send in tensors because it will try to send items as microbatches
for each GPU. Now that requires all the inputs to be tensors, so here I have written some
basic dumb heuristic that can set attention_mask and output_array to None if average of the values
in those tensors is -69 and -420 resp.</p>
<p>Image classification task does not require any <code class="docutils literal notranslate"><span class="pre">attention_mask</span></code> you can pass that as a tensor
with values <code class="docutils literal notranslate"><span class="pre">attention_mask</span> <span class="pre">=</span> <span class="pre">torch.tensor([-69.</span> <span class="pre">for</span> <span class="pre">_</span> <span class="pre">in</span> <span class="pre">range(batch_size)])</span></code> and similarly you
can send <code class="docutils literal notranslate"><span class="pre">output_array</span></code> as a tensor with values <code class="docutils literal notranslate"><span class="pre">output_array</span> <span class="pre">=</span> <span class="pre">torch.tensor([-420.</span> <span class="pre">for</span> <span class="pre">_</span> <span class="pre">in</span> <span class="pre">range(batch_size)])</span></code></p>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>config</strong> (<a class="reference internal" href="gperc.configs.html#gperc.configs.PerceiverConfig" title="gperc.configs.PerceiverConfig"><em>PerceiverConfig</em></a>) – Configuration object for the Perceiver</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>Model that can be used inplace of <code class="docutils literal notranslate"><span class="pre">Perceiver</span></code> but note that
it can only take in <code class="docutils literal notranslate"><span class="pre">torch.Tensor</span></code> objects and not <code class="docutils literal notranslate"><span class="pre">None</span></code>.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><code class="docutils literal notranslate"><span class="pre">torch.distributed.pipeline.sync.Pipe</span></code></p>
</dd>
</dl>
</dd></dl>
<dl class="py class">
<dt class="sig sig-object py" id="gperc.models.PerceiverMLM">
<em class="property"><span class="pre">class</span> </em><span class="sig-prename descclassname"><span class="pre">gperc.models.</span></span><span class="sig-name descname"><span class="pre">PerceiverMLM</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">Any</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">Any</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/gperc/models.html#PerceiverMLM"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#gperc.models.PerceiverMLM" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">torch.nn.</span></code></p>
<dl class="py method">
<dt class="sig sig-object py" id="gperc.models.PerceiverMLM.num_parameters">
<span class="sig-name descname"><span class="pre">num_parameters</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/gperc/models.html#PerceiverMLM.num_parameters"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#gperc.models.PerceiverMLM.num_parameters" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>
<dl class="py method">
<dt class="sig sig-object py" id="gperc.models.PerceiverMLM.forward">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/gperc/models.html#PerceiverMLM.forward"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#gperc.models.PerceiverMLM.forward" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>
</dd></dl>
<dl class="py class">
<dt class="sig sig-object py" id="gperc.models.PerceiverImage">
<em class="property"><span class="pre">class</span> </em><span class="sig-prename descclassname"><span class="pre">gperc.models.</span></span><span class="sig-name descname"><span class="pre">PerceiverImage</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">Any</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">Any</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/gperc/models.html#PerceiverImage"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#gperc.models.PerceiverImage" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">torch.nn.</span></code></p>
<dl class="py method">
<dt class="sig sig-object py" id="gperc.models.PerceiverImage.num_parameters">
<span class="sig-name descname"><span class="pre">num_parameters</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/gperc/models.html#PerceiverImage.num_parameters"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#gperc.models.PerceiverImage.num_parameters" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>
<dl class="py method">
<dt class="sig sig-object py" id="gperc.models.PerceiverImage.forward">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/gperc/models.html#PerceiverImage.forward"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#gperc.models.PerceiverImage.forward" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>
</dd></dl>
</section>
</section>
</section>

        </article>
      </div>
      <footer>
        
        <div class="related-pages">
          <a class="next-page" href="gperc.utils.html">
              <div class="page-info">
                <div class="context">
                  <span>Next</span>
                </div>
                <div class="title">Utils</div>
              </div>
              <svg><use href="#svg-arrow-right"></use></svg>
            </a>
          <a class="prev-page" href="gperc.data.html">
              <svg><use href="#svg-arrow-right"></use></svg>
              <div class="page-info">
                <div class="context">
                  <span>Previous</span>
                </div>
                
                <div class="title">gperc Data</div>
                
              </div>
            </a>
        </div>

        <div class="related-information">
              Copyright &#169; 2021, Yash Bonde |
            Built with <a href="https://www.sphinx-doc.org/">Sphinx</a>
              and
              <a class="muted-link" href="https://pradyunsg.me">@pradyunsg</a>'s
              <a href="https://github.com/pradyunsg/furo">Furo theme</a>. |
            <a class="muted-link" href="_sources/gperc.models.rst.txt"
               rel="nofollow">
              Show Source
            </a>
        </div>
        
      </footer>
    </div>
    <aside class="toc-drawer">
      
      
      <div class="toc-sticky toc-scroll">
        <div class="toc-title-container">
          <span class="toc-title">
            Contents
          </span>
        </div>
        <div class="toc-tree-container">
          <div class="toc-tree">
            <ul>
<li><a class="reference internal" href="#">gperc Architecture</a><ul>
<li><a class="reference internal" href="#perceiver-model">Perceiver Model</a><ul>
<li><a class="reference internal" href="#distributed">Distributed</a></li>
<li><a class="reference internal" href="#documentation">Documentation</a></li>
</ul>
</li>
</ul>
</li>
</ul>

          </div>
        </div>
      </div>
      
      
    </aside>
  </div>
</div><script data-url_root="./" id="documentation_options" src="_static/documentation_options.js"></script>
    <script src="_static/jquery.js"></script>
    <script src="_static/underscore.js"></script>
    <script src="_static/doctools.js"></script>
    <script src="_static/scripts/main.js"></script>
    </body>
</html>